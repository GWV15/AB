% !TeX encoding = UTF-8
% !TeX spellcheck = de_DE

\documentclass[DIV=9,numbers=noenddot]{scrartcl}

\usepackage[ngerman]{babel}
\usepackage{fontspec}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{comment}
\usepackage{hyperref}
\usepackage{calc}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usetikzlibrary{positioning}
\usepackage{float}
\usepackage[colorinlistoftodos]{todonotes}

\newcounter{blatt}
\setcounter{blatt}{8} % Nummer des Aufgabenblattes
\renewcommand{\thesection}{Exercise \arabic{blatt}.\arabic{section}}
\renewcommand{\thesubsection}{\arabic{subsection}.}
\renewcommand{\thesubsubsection}{(\alph{subsubsection})}

\title{GWV - Grundlagen der Wissensverarbeitung}
\subtitle{Tutorial \arabic{blatt}}
\author{Julian Tobergte, Melanie Budde,\\Maximilian Bauregger, Mohammad Oslani}
\date{\today}
\setcounter{section}{1}

\begin{document}
	\maketitle
	\section{Language Modelling}
		\setcounter{subsection}{1}
		\subsection{}
			Nehmen wir z.B. den folgenden generierten Satz: "`Linux gründende neue Herausforderung nicht mehr als Original-Sun-Speicherriegel. in diesen Ankündigungen gibt es auch mit der darauf, der."' Grammatikalisch ist hier einiges im Argen. Es existieren sinnvolle Wortkombinationen, wie "`nicht mehr als"' oder "`in diesen Ankündigungen"'. Eine Satzstruktur oder gar Sinn ist nicht vorhanden. Dies ergibt sich, da nur direkt benachbarte Worte miteinander verknüpft sind, Grammatik sich aber über den gesamten Satz erstreckt.
	\section{Diagnosis (cont.)}
	\section{Bayesian Probabilities}
		\paragraph{Variablen}
			\begin{align*}
				  S&:= \text{Schmuggler} &(s &= \text{ist Schmuggler}, \bar{s} = \text{ist kein Schmuggler})
				\\B&:= \text{Bellen des Hundes} &(b &= \text{Hund bellt}, \bar{b} = \text{Hund bellt nicht})
				\\F&:= \text{Fieber} &(f &= \text{hat Fieber}, \bar{f} = \text{hat kein Fieber})
				\\D&:= \text{Schwitzen} &(d &= \text{Person schwitzt}, \bar{d} = \text{Person schwitzt nicht})
			\end{align*}
		\paragraph{Gegebene Wahrscheinlichkeiten}
			\begin{align*}
				  &P(s)                 = 0.01  &\Rightarrow &P(\bar{s})                 = 0.99
				\\&P(b|s)               = 0.8   &\Rightarrow &P(\bar{b}|s)               = 0.2
				\\&P(b|\bar{s})         = 0.05  &\Rightarrow &P(\bar{b}|\bar{s})         = 0.95
				\\&P(d|\bar{s},\bar{f}) = 0     &\Rightarrow &P(\bar{d}|\bar{s},\bar{f}) = 1
				\\&P(d|s,\bar{f})       = 0.4   &\Rightarrow &P(\bar{d}|s,\bar{f})       = 0.6
				\\&P(d|\bar{s},f)       = 0.6   &\Rightarrow &P(\bar{d}|\bar{s},f)       = 0.4
				\\&P(d|s,f)             = 0.8   &\Rightarrow &P(\bar{d}|s,f)             = 0.2
				\\&P(f)                 = 0.013 &\Rightarrow &P(\bar{f})                 = 0.987
			\end{align*}
		\paragraph{Bayessches Netz}\hfill\\
			\begin{figure}[H]
				\centering
				\begin{tikzpicture}
					[->,>=stealth',shorten >=1pt,auto,node distance=4cm,thick,vars/.style={circle,draw,font=\sffamily\Large\bfseries}]
					\node[vars] (nB) {B};
					\node[vars] (nS) [above right of=nB] {S};
					\node[vars] (nD) [below right of=nS] {D};
					\node[vars] (nF) [above right of=nD] {F};
					\node       (tB) [below=0.1cm of nB,fill=white!25]{
						\begin{tabular}{ c | c | c }
							$P(B|S)$  & $b$    & $\bar{b}$ \\
							\hline
							$s$       & $0,8$  & $0.2$ \\
							$\bar{s}$ & $0.05$ & $0.95$ \\
						\end{tabular}
					};;
					\node       (tD) [below=0.1cm of nD,fill=white!25]{
						\begin{tabular}{ c | c | c }
							$P(D|S,F)$         & $d$   & $\bar{d}$ \\
							\hline
							$s,f$              & $0,8$ & $0.2$ \\
							$s,\bar{f}$        & $0.4$ & $0.6$ \\
							$\bar{s},f$        & $0.6$ & $0.4$ \\
							$\bar{s},\bar{f}$  & $0$   & $1$ \\
						\end{tabular}
					};;
					\node       (tS) [above=0.1cm of nS,fill=white!25]{$P(s) = 0.01$};;
					\node       (tF) [above=0.1cm of nF,fill=white!25]{$P(f) = 0.013$};;
					
					\path[every node/.style={font=\sffamily\small}]
						(nS) edge node {} (nB)
						     edge node {} (nD)
						(nF) edge node {} (nD);
				\end{tikzpicture}
			\end{figure}
		\paragraph{Formeln}\hfil\\
			Gesetz der totalen Wahrscheinlichkeiten:
			\[P(A) = P(A|B) \cdot P(B) + P(A|\bar{B}) \cdot P(\bar{B})\]
			Verallgemeinert:
			\[\sum_{j=1}^{\infty} P(A|B_{j}) \cdot P(B_{j}) = P(A)\]
			Satz von Bayes:
			\[P(B|A) = \frac{P(A|B) \cdot P(B)}{P(A)}\]
		\paragraph{Aufgaben}
			\begin{itemize}
				\item The probability that a person is a smuggler given the observation that the drug dog is barking:
				\par
				Gesucht wird der Wert für $P(s|b)$.
				\begin{align*}
					P(b|s) &= 0.8
					\\P(s) &= 0.01
					\\P(b) &= P(b|s) \cdot P(s) + P(b|\bar{s}) \cdot P(\bar{s})
					\\&= 0.8 \cdot 0.01 + 0.05 \cdot 0.99
					\\&= 0.0575
					\\
					\\P(s|b) &= \frac{P(b|s) \cdot P(s)}{P(b)}
					\\&=\frac{0.8 \cdot 0.01}{0.0575}
					\\&\approx 0.13913
				\end{align*}
				\item The probability that a suspect is sweating (without any prior observation):
				\par
				Gesucht wird der Wert für $P(d)$.
				\item The probability that a person is a smuggler given both the observations that
				that person is sweating and that the drug dog barked at him or her:
				\par
				Gesucht wird der Wert für $P(s|b,d)$.
			\end{itemize}
\end{document}
